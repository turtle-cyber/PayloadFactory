
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:14,  4.72s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:09<00:09,  4.97s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.93s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  3.66s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  4.12s/it]
INFO:ml_engine.exploit_generator:Regenerating exploit due to failure: No Crash detected. Payload might be incorrect or offset too small.
Setting `pad_token_id` to `eos_token_id`:128040 for open-end generation.
INFO:ml_engine.exploit_generator:Extracted payload: 64 bytes
2025-12-03 17:52:10,210 - INFO -   -> Exploit regenerated and saved. Retrying...
INFO:__main__:  -> Exploit regenerated and saved. Retrying...
2025-12-03 17:52:10,210 - INFO -   -> Running Fuzzer (Attempt 3/3)...
INFO:__main__:  -> Running Fuzzer (Attempt 3/3)...
INFO:ml_engine.fuzzing_module:Starting fuzzing session with 20 iterations.
WARNING:ml_engine.fuzzing_module:Iteration 18: High Latency (2012.65ms) detected!
2025-12-03 17:52:14,514 - INFO -   -> Running RL Agent...
INFO:__main__:  -> Running RL Agent...
INFO:ml_engine.rl_agent:Starting RL optimization...
INFO:ml_engine.db_manager:Connected to MongoDB: payloadfactoryDB
INFO:ml_engine.fuzzing_module:Fuzzer initialized for target: 192.168.1.157:8080
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2027.2ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2016.5ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2027.8ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2011.0ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.2) for 2031.1ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2025.0ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2026.4ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2020.0ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2012.4ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2010.3ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.0) for 2008.3ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.0) for 2009.7ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2020.8ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2022.8ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2025.6ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2028.1ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.0) for 2007.9ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2026.8ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2015.6ms response.
INFO:ml_engine.rl_agent:RL Agent: Latency Bonus (+9.1) for 2027.6ms response.
2025-12-03 17:52:54,924 - INFO -   -> Optimization complete for exploit_BackportEnglish.java_0_20251203_172229.py
INFO:__main__:  -> Optimization complete for exploit_BackportEnglish.java_0_20251203_172229.py
2025-12-03 17:52:54,924 - INFO - Optimizing exploit_BeanRepository.java_0_20251203_171534.py...
INFO:__main__:Optimizing exploit_BeanRepository.java_0_20251203_171534.py...
2025-12-03 17:52:54,925 - INFO -   -> Running Fuzzer (Attempt 1/3)...
INFO:__main__:  -> Running Fuzzer (Attempt 1/3)...
INFO:ml_engine.fuzzing_module:Starting fuzzing session with 20 iterations.
WARNING:ml_engine.fuzzing_module:Iteration 6: High Latency (2015.51ms) detected!
WARNING:ml_engine.fuzzing_module:Iteration 19: High Latency (2026.89ms) detected!
2025-12-03 17:53:01,371 - WARNING -   -> Fuzzing failed (0 crashes). Initiating Self-Healing...
WARNING:__main__:  -> Fuzzing failed (0 crashes). Initiating Self-Healing...
INFO:ml_engine.exploit_generator:Loading Hermes 3 model from E:\GRAND_AI_MODELS\hermes-3-llama-3.1-8b on cuda (4-bit quantized)
ERROR:ml_engine.exploit_generator:Failed to load model: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details.
2025-12-03 17:53:01,650 - ERROR - Error optimizing exploit_BeanRepository.java_0_20251203_171534.py: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details.
ERROR:__main__:Error optimizing exploit_BeanRepository.java_0_20251203_171534.py: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details.
2025-12-03 17:53:01,658 - INFO - Optimizing exploit_CopyParentClassLoaderRule.java_0_20251203_165749.py...
INFO:__main__:Optimizing exploit_CopyParentClassLoaderRule.java_0_20251203_165749.py...
2025-12-03 17:53:01,658 - INFO -   -> Running Fuzzer (Attempt 1/3)...
INFO:__main__:  -> Running Fuzzer (Attempt 1/3)...
INFO:ml_engine.fuzzing_module:Starting fuzzing session with 20 iterations.
WARNING:ml_engine.fuzzing_module:Iteration 1: High Latency (2022.96ms) detected!
WARNING:ml_engine.fuzzing_module:Iteration 19: High Latency (2026.96ms) detected!
2025-12-03 17:53:08,054 - WARNING -   -> Fuzzing failed (0 crashes). Initiating Self-Healing...
WARNING:__main__:  -> Fuzzing failed (0 crashes). Initiating Self-Healing...
INFO:ml_engine.exploit_generator:Loading Hermes 3 model from E:\GRAND_AI_MODELS\hermes-3-llama-3.1-8b on cuda (4-bit quantized)
ERROR:ml_engine.exploit_generator:Failed to load model: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details.
2025-12-03 17:53:08,312 - ERROR - Error optimizing exploit_CopyParentClassLoaderRule.java_0_20251203_165749.py: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details.
ERROR:__main__:Error optimizing exploit_CopyParentClassLoaderRule.java_0_20251203_165749.py: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `llm_int8_enable_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details.
2025-12-03 17:53:08,321 - INFO - Stage 3 Complete.
INFO:__main__:Stage 3 Complete.
2025-12-03 17:53:09,973 - INFO - scan_stage_3.py completed successfully.
2025-12-03 17:53:09,973 - INFO - ALL STAGES COMPLETED SUCCESSFULLY.
2025-12-03 17:53:09,977 - INFO - MongoDB connection closed.

--- Scan Completed Successfully ---
